name: Health Check

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:

jobs:
  health-check:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        python -c "import nltk; nltk.download('punkt', quiet=True); nltk.download('stopwords', quiet=True); nltk.download('wordnet', quiet=True)"
    
    - name: Create directories
      run: |
        mkdir -p models/current logs data/raw
    
    - name: Create test models
      run: |
        python << 'EOF'
        import pickle
        import json
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import LabelEncoder
        import numpy as np

        print("Creating test models for health check...")

        # Create minimal test models that work
        tfidf = TfidfVectorizer(max_features=1000)
        test_texts = [
            'this is a positive message',
            'this is a negative message', 
            'this is a neutral message'
        ]
        tfidf.fit(test_texts)

        # Create label encoder
        le = LabelEncoder()
        test_labels = ['positive', 'negative', 'neutral']
        le.fit(test_labels)

        # Create and train a simple model
        model = LogisticRegression(random_state=42)
        X_test = tfidf.transform(test_texts)
        y_test = le.transform(test_labels)
        model.fit(X_test, y_test)

        # Save all models
        with open('models/current/tfidf_vectorizer.pkl', 'wb') as f:
            pickle.dump(tfidf, f)
        
        with open('models/current/label_encoder.pkl', 'wb') as f:
            pickle.dump(le, f)
        
        with open('models/current/logistic_regression_model.pkl', 'wb') as f:
            pickle.dump(model, f)

        # Save metadata
        metadata = {
            'accuracy': 0.85,
            'timestamp': '20250924_000000',
            'model_type': 'logistic_regression',
            'training_date': '2025-09-24T00:00:00',
            'source': 'health_check_test'
        }
        
        with open('models/current/metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)

        print("‚úÖ Test models created successfully")
        EOF
    
    - name: Test application startup
      run: |
        echo "üöÄ Testing application startup..."
        
        # Start the app in background
        python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        APP_PID=$!
        
        # Wait for app to start
        echo "‚è≥ Waiting for application to start..."
        sleep 15
        
        # Test if app is running
        if ! ps -p $APP_PID > /dev/null; then
            echo "‚ùå Application failed to start"
            exit 1
        fi
        
        echo "‚úÖ Application started successfully (PID: $APP_PID)"
    
    - name: Run health checks
      run: |
        echo "üè• Running comprehensive health checks..."
        
        python << 'EOF'
        import requests
        import time
        import json

        # Wait a bit more for the app to be fully ready
        time.sleep(10)
        
        try:
            # Test 1: Health endpoint
            print("Testing health endpoint...")
            health_response = requests.get('http://localhost:8000/health', timeout=15)
            print(f"Health Status: {health_response.status_code}")
            
            if health_response.status_code == 200:
                health_data = health_response.json()
                print(f"Health Data: {json.dumps(health_data, indent=2)}")
                print("‚úÖ Health check passed")
            else:
                print(f"‚ùå Health check failed with status: {health_response.status_code}")
                exit(1)
            
            # Test 2: Prediction endpoint
            print("\nTesting prediction endpoint...")
            pred_data = {"text": "This is a great project with excellent results"}
            pred_response = requests.post(
                'http://localhost:8000/api/predict',
                json=pred_data,
                timeout=15
            )
            print(f"Prediction Status: {pred_response.status_code}")
            
            if pred_response.status_code == 200:
                pred_result = pred_response.json()
                print(f"Prediction Result: {json.dumps(pred_result, indent=2)}")
                
                # Validate prediction structure
                if 'sentiment' in pred_result and 'confidence' in pred_result:
                    print("‚úÖ Prediction endpoint working correctly")
                else:
                    print("‚ùå Prediction response missing required fields")
                    exit(1)
            else:
                print(f"‚ùå Prediction failed with status: {pred_response.status_code}")
                print(f"Response: {pred_response.text}")
                exit(1)
            
            # Test 3: Web interface
            print("\nTesting web interface...")
            web_response = requests.get('http://localhost:8000/', timeout=15)
            print(f"Web Interface Status: {web_response.status_code}")
            
            if web_response.status_code == 200:
                print("‚úÖ Web interface accessible")
            else:
                print(f"‚ö†Ô∏è Web interface returned status: {web_response.status_code}")
            
            print("\nüéâ All health checks completed successfully!")
            
        except Exception as e:
            print(f"‚ùå Health check failed with error: {str(e)}")
            import traceback
            traceback.print_exc()
            exit(1)
        EOF
    
    - name: Cleanup
      if: always()
      run: |
        echo "üßπ Cleaning up..."
        # Kill any remaining processes
        pkill -f "uvicorn app.main:app" || true
        echo "‚úÖ Cleanup completed"
    
    - name: Create summary
      if: always()
      run: |
        echo "## üè• Health Check Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Date**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Python Version**: 3.11" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "models/current/metadata.json" ]; then
            echo "### üìä Model Information:" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            cat models/current/metadata.json >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ‚úÖ Tests Performed:" >> $GITHUB_STEP_SUMMARY
        echo "- Health endpoint (`/health`)" >> $GITHUB_STEP_SUMMARY
        echo "- Prediction endpoint (`/api/predict`)" >> $GITHUB_STEP_SUMMARY
        echo "- Web interface (`/`)" >> $GITHUB_STEP_SUMMARY
        echo "- Model loading and functionality" >> $GITHUB_STEP_SUMMARY

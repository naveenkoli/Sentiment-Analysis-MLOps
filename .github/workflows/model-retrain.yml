name: ü§ñ Automated Model Retraining (Fixed)

on:
  schedule:
    - cron: '*/5 * * * *'  # Every 5 minutes (corrected comment)
  workflow_dispatch:  # Manual trigger
  push:
    paths:
      - 'data/raw/**'  # Trigger on new data

jobs:
  retrain:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4  # Updated version
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'  # Updated Python version
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        python -c "import nltk; nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt')"
        
    - name: Create directories
      run: |
        mkdir -p data/{raw,processed,archive} models/{current,training,backup} logs
        
    - name: Add sample data if none exists
      run: |
        if [ ! -f "data/raw/sample_data.csv" ]; then
          echo "Creating sample data for retraining..."
          cat > data/raw/sample_data.csv << 'EOD'
        Remarks,Sentiment,Company Name,Opportunity Name
        "Great progress on project",positive,"TechCorp","Platform"
        "Client very satisfied",positive,"DataSys","Analytics"
        "Excellent work done",positive,"CloudInc","Migration"
        "No response from client",negative,"TechCorp","Platform"
        "Project delayed significantly",negative,"DataSys","Analytics"
        "Client unhappy with results",negative,"CloudInc","Migration"
        "Meeting next week",neutral,"TechCorp","Platform"
        "Status under review",neutral,"DataSys","Analytics"
        "Planning next phase",neutral,"CloudInc","Migration"
        EOD
        fi
        
    - name: Check for existing models
      run: |
        if [ ! -f "models/current/metadata.json" ]; then
          echo "No current models found"
          if [ -f "models/tfidf_vectorizer.pkl" ]; then
            cp models/*.pkl models/current/
            echo '{
              "timestamp": "initial", 
              "accuracy": 0.85,
              "source": "existing_models"
            }' > models/current/metadata.json
          fi
        fi
        
    - name: Debug - Check files before training
      run: |
        echo "üìä Data files available:"
        find data/raw -name "*.csv" -o -name "*.xlsx" 2>/dev/null || echo "No data files found"
        echo ""
        echo "ü§ñ Training script exists:"
        ls -la scripts/train_model.py 2>/dev/null || echo "Training script not found"
        echo ""
        echo "üì¶ Current models:"
        ls -la models/current/ 2>/dev/null || echo "No current models"
        
    - name: Train new model
      id: training
      run: |
        echo "ü§ñ Starting model training..."
        if [ -f "scripts/train_model.py" ]; then
          python scripts/train_model.py
          echo "training_result=success" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Training script not found, creating simple training..."
          # Fallback simple training
          python << 'EOF'
        import pandas as pd
        import pickle
        import json
        from datetime import datetime
        from pathlib import Path
        from sklearn.model_selection import train_test_split
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import LabelEncoder
        from sklearn.metrics import accuracy_score
        import re
        
        def preprocess_text(text):
            if pd.isna(text):
                return ""
            return re.sub(r'[^a-zA-Z\s]', '', str(text).lower()).strip()
        
        # Load data
        data_files = list(Path("data/raw").glob("*.csv")) + list(Path("data/raw").glob("*.xlsx"))
        if not data_files:
            print("No data files found")
            exit(1)
            
        all_data = []
        for file in data_files:
            if file.suffix == '.csv':
                df = pd.read_csv(file)
            else:
                df = pd.read_excel(file)
            all_data.append(df)
        
        combined_df = pd.concat(all_data, ignore_index=True)
        combined_df = combined_df.dropna(subset=['Remarks', 'Sentiment'])
        combined_df['cleaned_text'] = combined_df['Remarks'].apply(preprocess_text)
        
        # Train
        X = combined_df['cleaned_text']
        y = combined_df['Sentiment']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        
        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        X_train_tfidf = tfidf.fit_transform(X_train)
        X_test_tfidf = tfidf.transform(X_test)
        
        le = LabelEncoder()
        y_train_encoded = le.fit_transform(y_train)
        y_test_encoded = le.transform(y_test)
        
        model = LogisticRegression(max_iter=1000, random_state=42)
        model.fit(X_train_tfidf, y_train_encoded)
        
        accuracy = accuracy_score(y_test_encoded, model.predict(X_test_tfidf))
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Save to training directory
        training_dir = Path("models/training") / timestamp
        training_dir.mkdir(parents=True, exist_ok=True)
        
        with open(training_dir / "tfidf_vectorizer.pkl", "wb") as f:
            pickle.dump(tfidf, f)
        with open(training_dir / "label_encoder.pkl", "wb") as f:
            pickle.dump(le, f)
        with open(training_dir / "logistic_regression_model.pkl", "wb") as f:
            pickle.dump(model, f)
        
        metadata = {
            "timestamp": timestamp,
            "accuracy": float(accuracy),
            "model_type": "logistic_regression",
            "training_date": datetime.now().isoformat(),
            "data_size": len(combined_df)
        }
        
        with open(training_dir / "metadata.json", "w") as f:
            json.dump(metadata, f, indent=2)
        
        print(f"Training completed: {timestamp}, Accuracy: {accuracy:.4f}")
        EOF
          echo "training_result=fallback_success" >> $GITHUB_OUTPUT
        fi
        
    - name: Find latest trained model
      id: find_model
      run: |
        if [ -d "models/training" ] && [ "$(ls -A models/training)" ]; then
          LATEST_MODEL=$(ls -t models/training | head -1)
          echo "latest_model=$LATEST_MODEL" >> $GITHUB_OUTPUT
          echo "model_found=true" >> $GITHUB_OUTPUT
          echo "‚úÖ Found latest model: $LATEST_MODEL"
        else
          echo "model_found=false" >> $GITHUB_OUTPUT
          echo "‚ùå No trained models found"
        fi
        
    - name: Validate model (if script exists)
      if: steps.find_model.outputs.model_found == 'true'
      run: |
        if [ -f "scripts/validate_model.py" ]; then
          python scripts/validate_model.py models/training/${{ steps.find_model.outputs.latest_model }}
        else
          echo "‚ÑπÔ∏è No validation script found, skipping validation"
        fi
      continue-on-error: true
      
    - name: Deploy model
      if: steps.find_model.outputs.model_found == 'true'
      run: |
        if [ -f "scripts/deploy_model.py" ]; then
          python scripts/deploy_model.py models/training/${{ steps.find_model.outputs.latest_model }}
        else
          echo "üìã No deploy script, manually copying models..."
          cp models/training/${{ steps.find_model.outputs.latest_model }}/*.pkl models/current/
          cp models/training/${{ steps.find_model.outputs.latest_model }}/metadata.json models/current/
        fi
        
    - name: Commit updated models
      if: steps.find_model.outputs.model_found == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action [Every 5min]"
        git add models/current/ models/training/ models/backup/
        
        if ! git diff --staged --quiet; then
          git commit -m "ü§ñ Auto-retrain every 5min: ${{ steps.find_model.outputs.latest_model }} ($(date +'%Y-%m-%d %H:%M:%S UTC'))"
          git push
          echo "‚úÖ Models updated and pushed!"
        else
          echo "‚ÑπÔ∏è No changes to commit"
        fi
        
    - name: Create deployment summary
      run: |
        echo "## ü§ñ Automated Model Retraining (Every 5 Minutes)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Date**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Training**: ${{ steps.training.outputs.training_result }}" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.find_model.outputs.model_found }}" == "true" ]; then
          echo "- **Status**: ‚úÖ New model trained and deployed" >> $GITHUB_STEP_SUMMARY
          echo "- **Model**: ${{ steps.find_model.outputs.latest_model }}" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Status**: ‚ùå No model was trained" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- **Next Run**: In 5 minutes" >> $GITHUB_STEP_SUMMARY
